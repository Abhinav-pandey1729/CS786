{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0d070ec",
   "metadata": {},
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c4ffba",
   "metadata": {},
   "source": [
    "## Generate Training and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7dc7c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists: ./generated_images_v2\n",
      "Image saved at: ./generated_images_v2/X_0.png\n",
      "Image saved at: ./generated_images_v2/Triangle_1.png\n",
      "Image saved at: ./generated_images_v2/U_2.png\n",
      "Image saved at: ./generated_images_v2/I_3.png\n",
      "Image saved at: ./generated_images_v2/Triangle_4.png\n",
      "Image saved at: ./generated_images_v2/Square_5.png\n",
      "Image saved at: ./generated_images_v2/T_6.png\n",
      "Image saved at: ./generated_images_v2/Star_7.png\n",
      "Image saved at: ./generated_images_v2/T_8.png\n",
      "Image saved at: ./generated_images_v2/X_9.png\n",
      "Image saved at: ./generated_images_v2/Star_10.png\n",
      "Image saved at: ./generated_images_v2/X_11.png\n",
      "Image saved at: ./generated_images_v2/Star_12.png\n",
      "Image saved at: ./generated_images_v2/X_13.png\n",
      "Image saved at: ./generated_images_v2/Triangle_14.png\n",
      "Image saved at: ./generated_images_v2/Star_15.png\n",
      "Image saved at: ./generated_images_v2/Star_16.png\n",
      "Image saved at: ./generated_images_v2/Triangle_17.png\n",
      "Image saved at: ./generated_images_v2/U_18.png\n",
      "Image saved at: ./generated_images_v2/L_19.png\n",
      "Image saved at: ./generated_images_v2/T_20.png\n",
      "Image saved at: ./generated_images_v2/I_21.png\n",
      "Image saved at: ./generated_images_v2/T_22.png\n",
      "Image saved at: ./generated_images_v2/Triangle_23.png\n",
      "Image saved at: ./generated_images_v2/X_24.png\n",
      "Image saved at: ./generated_images_v2/Square_25.png\n",
      "Image saved at: ./generated_images_v2/X_26.png\n",
      "Image saved at: ./generated_images_v2/U_27.png\n",
      "Image saved at: ./generated_images_v2/Square_28.png\n",
      "Image saved at: ./generated_images_v2/Triangle_29.png\n",
      "Image saved at: ./generated_images_v2/Triangle_30.png\n",
      "Image saved at: ./generated_images_v2/L_31.png\n",
      "Image saved at: ./generated_images_v2/Triangle_32.png\n",
      "Image saved at: ./generated_images_v2/X_33.png\n",
      "Image saved at: ./generated_images_v2/I_34.png\n",
      "Image saved at: ./generated_images_v2/Triangle_35.png\n",
      "Image saved at: ./generated_images_v2/U_36.png\n",
      "Image saved at: ./generated_images_v2/L_37.png\n",
      "Image saved at: ./generated_images_v2/Square_38.png\n",
      "Image saved at: ./generated_images_v2/Triangle_39.png\n",
      "Image saved at: ./generated_images_v2/Triangle_40.png\n",
      "Image saved at: ./generated_images_v2/T_41.png\n",
      "Image saved at: ./generated_images_v2/U_42.png\n",
      "Image saved at: ./generated_images_v2/T_43.png\n",
      "Image saved at: ./generated_images_v2/Triangle_44.png\n",
      "Image saved at: ./generated_images_v2/T_45.png\n",
      "Image saved at: ./generated_images_v2/I_46.png\n",
      "Image saved at: ./generated_images_v2/T_47.png\n",
      "Image saved at: ./generated_images_v2/L_48.png\n",
      "Image saved at: ./generated_images_v2/X_49.png\n",
      "Image saved at: ./generated_images_v2/X_50.png\n",
      "Image saved at: ./generated_images_v2/I_51.png\n",
      "Image saved at: ./generated_images_v2/U_52.png\n",
      "Image saved at: ./generated_images_v2/Triangle_53.png\n",
      "Image saved at: ./generated_images_v2/Square_54.png\n",
      "Image saved at: ./generated_images_v2/Triangle_55.png\n",
      "Image saved at: ./generated_images_v2/U_56.png\n",
      "Image saved at: ./generated_images_v2/L_57.png\n",
      "Image saved at: ./generated_images_v2/U_58.png\n",
      "Image saved at: ./generated_images_v2/I_59.png\n",
      "Image saved at: ./generated_images_v2/U_60.png\n",
      "Image saved at: ./generated_images_v2/Square_61.png\n",
      "Image saved at: ./generated_images_v2/Square_62.png\n",
      "Image saved at: ./generated_images_v2/X_63.png\n",
      "Image saved at: ./generated_images_v2/L_64.png\n",
      "Image saved at: ./generated_images_v2/X_65.png\n",
      "Image saved at: ./generated_images_v2/Square_66.png\n",
      "Image saved at: ./generated_images_v2/T_67.png\n",
      "Image saved at: ./generated_images_v2/L_68.png\n",
      "Image saved at: ./generated_images_v2/T_69.png\n",
      "Image saved at: ./generated_images_v2/L_70.png\n",
      "Image saved at: ./generated_images_v2/Square_71.png\n",
      "Image saved at: ./generated_images_v2/U_72.png\n",
      "Image saved at: ./generated_images_v2/L_73.png\n",
      "Image saved at: ./generated_images_v2/U_74.png\n",
      "Image saved at: ./generated_images_v2/Square_75.png\n",
      "Image saved at: ./generated_images_v2/L_76.png\n",
      "Image saved at: ./generated_images_v2/X_77.png\n",
      "Image saved at: ./generated_images_v2/Star_78.png\n",
      "Image saved at: ./generated_images_v2/I_79.png\n",
      "Image saved at: ./generated_images_v2/L_80.png\n",
      "Image saved at: ./generated_images_v2/Star_81.png\n",
      "Image saved at: ./generated_images_v2/L_82.png\n",
      "Image saved at: ./generated_images_v2/T_83.png\n",
      "Image saved at: ./generated_images_v2/T_84.png\n",
      "Image saved at: ./generated_images_v2/Star_85.png\n",
      "Image saved at: ./generated_images_v2/Square_86.png\n",
      "Image saved at: ./generated_images_v2/U_87.png\n",
      "Image saved at: ./generated_images_v2/X_88.png\n",
      "Image saved at: ./generated_images_v2/T_89.png\n",
      "Image saved at: ./generated_images_v2/L_90.png\n",
      "Image saved at: ./generated_images_v2/I_91.png\n",
      "Image saved at: ./generated_images_v2/Star_92.png\n",
      "Image saved at: ./generated_images_v2/X_93.png\n",
      "Image saved at: ./generated_images_v2/I_94.png\n",
      "Image saved at: ./generated_images_v2/U_95.png\n",
      "Image saved at: ./generated_images_v2/I_96.png\n",
      "Image saved at: ./generated_images_v2/T_97.png\n",
      "Image saved at: ./generated_images_v2/U_98.png\n",
      "Image saved at: ./generated_images_v2/I_99.png\n",
      "Directory already exists: ./generated_images_test_v2\n",
      "Image saved at: ./generated_images_test_v2/T_0.png\n",
      "Image saved at: ./generated_images_test_v2/Triangle_1.png\n",
      "Image saved at: ./generated_images_test_v2/Star_2.png\n",
      "Image saved at: ./generated_images_test_v2/I_3.png\n",
      "Image saved at: ./generated_images_test_v2/L_4.png\n",
      "Image saved at: ./generated_images_test_v2/T_5.png\n",
      "Image saved at: ./generated_images_test_v2/Triangle_6.png\n",
      "Image saved at: ./generated_images_test_v2/Square_7.png\n",
      "Image saved at: ./generated_images_test_v2/L_8.png\n",
      "Image saved at: ./generated_images_test_v2/T_9.png\n",
      "Image saved at: ./generated_images_test_v2/Triangle_10.png\n",
      "Image saved at: ./generated_images_test_v2/X_11.png\n",
      "Image saved at: ./generated_images_test_v2/Triangle_12.png\n",
      "Image saved at: ./generated_images_test_v2/L_13.png\n",
      "Image saved at: ./generated_images_test_v2/U_14.png\n",
      "Image saved at: ./generated_images_test_v2/T_15.png\n",
      "Image saved at: ./generated_images_test_v2/U_16.png\n",
      "Image saved at: ./generated_images_test_v2/I_17.png\n",
      "Image saved at: ./generated_images_test_v2/U_18.png\n",
      "Image saved at: ./generated_images_test_v2/Square_19.png\n",
      "Image saved at: ./generated_images_test_v2/X_20.png\n",
      "Image saved at: ./generated_images_test_v2/X_21.png\n",
      "Image saved at: ./generated_images_test_v2/Square_22.png\n",
      "Image saved at: ./generated_images_test_v2/X_23.png\n",
      "Image saved at: ./generated_images_test_v2/I_24.png\n",
      "Image saved at: ./generated_images_test_v2/L_25.png\n",
      "Image saved at: ./generated_images_test_v2/Triangle_26.png\n",
      "Image saved at: ./generated_images_test_v2/L_27.png\n",
      "Image saved at: ./generated_images_test_v2/Square_28.png\n",
      "Image saved at: ./generated_images_test_v2/Star_29.png\n",
      "Image saved at: ./generated_images_test_v2/Star_30.png\n",
      "Image saved at: ./generated_images_test_v2/T_31.png\n",
      "Image saved at: ./generated_images_test_v2/I_32.png\n",
      "Image saved at: ./generated_images_test_v2/Star_33.png\n",
      "Image saved at: ./generated_images_test_v2/Triangle_34.png\n",
      "Image saved at: ./generated_images_test_v2/X_35.png\n",
      "Image saved at: ./generated_images_test_v2/X_36.png\n",
      "Image saved at: ./generated_images_test_v2/Square_37.png\n",
      "Image saved at: ./generated_images_test_v2/T_38.png\n",
      "Image saved at: ./generated_images_test_v2/U_39.png\n",
      "Image saved at: ./generated_images_test_v2/X_40.png\n",
      "Image saved at: ./generated_images_test_v2/Square_41.png\n",
      "Image saved at: ./generated_images_test_v2/Triangle_42.png\n",
      "Image saved at: ./generated_images_test_v2/I_43.png\n",
      "Image saved at: ./generated_images_test_v2/I_44.png\n",
      "Image saved at: ./generated_images_test_v2/I_45.png\n",
      "Image saved at: ./generated_images_test_v2/T_46.png\n",
      "Image saved at: ./generated_images_test_v2/T_47.png\n",
      "Image saved at: ./generated_images_test_v2/L_48.png\n",
      "Image saved at: ./generated_images_test_v2/X_49.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# Function to ensure the directory for storing data exists\n",
    "def ensure_data_dir_exists(dir_path):\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "        print(f\"Directory created: {dir_path}\")\n",
    "    else:\n",
    "        print(f\"Directory already exists: {dir_path}\")\n",
    "\n",
    "# Function to draw a star shape\n",
    "def draw_star(draw, center, size):\n",
    "    x, y = center\n",
    "    points = [\n",
    "        (x, y - size),  # Top\n",
    "        (x + size * 0.5, y - size * 0.3),\n",
    "        (x + size, y),\n",
    "        (x + size * 0.5, y + size * 0.3),\n",
    "        (x, y + size),\n",
    "        (x - size * 0.5, y + size * 0.3),\n",
    "        (x - size, y),\n",
    "        (x - size * 0.5, y - size * 0.3)\n",
    "    ]\n",
    "    draw.polygon(points, fill=0)\n",
    "\n",
    "# Function to create images of macro-objects from micro-objects\n",
    "def create_macro_image(shape, layout, image_size=(100, 100), save_path=\"output_image.png\"):\n",
    "    img = Image.new('L', image_size, 255)  # White background image\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    for coords in layout:\n",
    "        if shape == 'circle':\n",
    "            draw.ellipse([coords, (coords[0] + 5, coords[1] + 5)], fill=0)  # Create circle objects\n",
    "        elif shape == 'square':\n",
    "            draw.rectangle([coords, (coords[0] + 5, coords[1] + 5)], fill=0)  # Create square objects\n",
    "        elif shape == 'triangle':\n",
    "            draw.polygon([coords, (coords[0] + 5, coords[1]), (coords[0] + 2.5, coords[1] - 5)], fill=0)  # Triangle\n",
    "        elif shape == 'star':\n",
    "            draw_star(draw, coords, size=5)  # Draw a star\n",
    "\n",
    "    img.save(save_path)\n",
    "    print(f\"Image saved at: {save_path}\")\n",
    "\n",
    "# Generate macro-object images with predefined patterns\n",
    "def generate_macro_images(output_dir, image_count=100):\n",
    "    ensure_data_dir_exists(output_dir)\n",
    "\n",
    "    # Define macro-object patterns for various shapes\n",
    "    macro_shapes = {\n",
    "        'I': [(40, 10), (40, 20), (40, 30), (40, 40), (40, 50)],  # Pattern \"I\"\n",
    "        'L': [(10, 10), (10, 20), (10, 30), (10, 40), (10, 50), (20, 50), (30, 50)],  # Pattern \"L\"\n",
    "        'T': [(30, 10), (30, 20), (30, 30), (30, 40), (20, 10), (40, 10)],  # Pattern \"T\"\n",
    "        'X': [(20, 20), (30, 30), (40, 40), (40, 20), (20, 40)],  # Pattern \"X\"\n",
    "        'U': [(10, 10), (10, 30), (10, 40), (30, 40), (50, 40), (50, 30), (50, 10)],  # Pattern \"U\"\n",
    "        'Triangle': [(25, 10), (10, 40), (40, 40)],  # Triangle shape\n",
    "        'Star': [(25, 20), (15, 40), (35, 40)],  # Star shape layout\n",
    "        'Square': [(20, 20), (20, 40), (40, 20), (40, 40)],  # Square shape layout\n",
    "    }\n",
    "\n",
    "    # Assign random labels for each generated macro-object\n",
    "    labels = list(macro_shapes.keys())\n",
    "    shapes = ['circle', 'square', 'triangle', 'star']  # New shape options\n",
    "    for i in range(image_count):\n",
    "        label = random.choice(labels)\n",
    "        pattern = macro_shapes[label]\n",
    "        shape = random.choice(shapes)  # Choose a random shape for each pattern\n",
    "\n",
    "        # Generate the macro-object from micro-object shapes\n",
    "        output_image = os.path.join(output_dir, f\"{label}_{i}.png\")\n",
    "        create_macro_image(shape, pattern, save_path=output_image)\n",
    "\n",
    "# Run the macro-object generator for training data\n",
    "image_output_dir = './generated_images_v2'  # Updated training data directory\n",
    "generate_macro_images(image_output_dir, image_count=100)\n",
    "\n",
    "# Run the macro-object generator for test data\n",
    "test_output_dir = './generated_images_test_v2'  # Updated test data directory\n",
    "generate_macro_images(test_output_dir, image_count=50)  # Generate fewer images for testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1751545",
   "metadata": {},
   "source": [
    "## Define Dataset Class and CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8574cf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Define the custom dataset class to load images and labels\n",
    "class MacroObjectDataset(Dataset):\n",
    "    def __init__(self, folder, transform=None):\n",
    "        self.folder = folder\n",
    "        self.image_files = os.listdir(folder)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_file = os.path.join(self.folder, self.image_files[index])\n",
    "        image = Image.open(image_file).convert('L')  # Convert image to grayscale\n",
    "        label = self.image_files[index].split('_')[0]\n",
    "        label_dict = {\"I\": 0, \"L\": 1, \"T\": 2, \"X\": 3, \"U\": 4, \"Triangle\": 5, \"Star\": 6, \"Square\": 7}  # Added 'Square'\n",
    "        label_id = label_dict[label]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label_id\n",
    "\n",
    "# Define the CNN architecture\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=8):  # Change from 7 to 8\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 25 * 25, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)  # Updated num_classes to 8\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.ReLU()(self.conv1(x)))\n",
    "        x = self.pool(nn.ReLU()(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 25 * 25)  # Flatten tensor for fully connected layer\n",
    "        x = nn.ReLU()(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eebee0d",
   "metadata": {},
   "source": [
    "## Load Dataset and Define Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ffa255e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleCNN(num_classes=8).to(device)  # Updated to 8 classes\n",
    "\n",
    "# Define the transformation for images\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((100, 100)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load the training dataset and create the DataLoader\n",
    "train_dataset = MacroObjectDataset('./generated_images_v2', transform=image_transform)  # Updated training directory\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Model, loss, and optimizer\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43258f4",
   "metadata": {},
   "source": [
    "## Train the Model, Print Epoch-wise Accuracy Table & Evaluate the Model on the Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51e9aecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.7754, Accuracy: 44.77%\n",
      "Epoch [2/10], Loss: 0.2617, Accuracy: 97.05%\n",
      "Epoch [3/10], Loss: 0.0159, Accuracy: 100.00%\n",
      "Epoch [4/10], Loss: 0.0024, Accuracy: 100.00%\n",
      "Epoch [5/10], Loss: 0.0010, Accuracy: 100.00%\n",
      "Epoch [6/10], Loss: 0.0005, Accuracy: 100.00%\n",
      "Epoch [7/10], Loss: 0.0004, Accuracy: 100.00%\n",
      "Epoch [8/10], Loss: 0.0003, Accuracy: 100.00%\n",
      "Epoch [9/10], Loss: 0.0003, Accuracy: 100.00%\n",
      "Epoch [10/10], Loss: 0.0002, Accuracy: 100.00%\n",
      "\n",
      "Epoch vs Accuracy:\n",
      "Epoch      Accuracy (%)   \n",
      "1          44.77          \n",
      "2          97.05          \n",
      "3          100.00         \n",
      "4          100.00         \n",
      "5          100.00         \n",
      "6          100.00         \n",
      "7          100.00         \n",
      "8          100.00         \n",
      "9          100.00         \n",
      "10         100.00         \n",
      "Test Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store accuracies for each epoch\n",
    "epoch_accuracies = {}\n",
    "\n",
    "# Function to train the CNN model\n",
    "def train_model(model, data_loader, loss_fn, optimizer, epochs=10):\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct_preds = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        for images, labels in data_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Calculate running accuracy\n",
    "            running_loss += loss.item()\n",
    "            _, predictions = torch.max(outputs.data, 1)\n",
    "            total_samples += labels.size(0)\n",
    "            correct_preds += (predictions == labels).sum().item()\n",
    "\n",
    "        accuracy = 100 * correct_preds / total_samples\n",
    "        epoch_accuracies[epoch + 1] = accuracy  # Store accuracy for the epoch\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(data_loader):.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Train the model and print accuracy table\n",
    "train_model(model, train_loader, loss_function, optimizer)\n",
    "\n",
    "# Print results as a table\n",
    "print(\"\\nEpoch vs Accuracy:\")\n",
    "print(\"{:<10} {:<15}\".format(\"Epoch\", \"Accuracy (%)\"))\n",
    "for epoch, accuracy in epoch_accuracies.items():\n",
    "    print(\"{:<10} {:<15.2f}\".format(epoch, accuracy))\n",
    "\n",
    "# Testing Function\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Test Accuracy: {100 * correct / total:.2f}%')\n",
    "\n",
    "# Load the test dataset and create the DataLoader\n",
    "test_dataset = MacroObjectDataset('./generated_images_test_v2', transform=image_transform)  # Updated test directory\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Test the model after training\n",
    "test_model(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cf15cb",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbe2a8e",
   "metadata": {},
   "source": [
    "## Generate Dataset Using the Principle of Continuity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "310d62b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists: ./data_continuity\n",
      "Saved image: ./data_continuity/Curve_Line_0.png\n",
      "Saved image: ./data_continuity/Zigzag_Line_1.png\n",
      "Saved image: ./data_continuity/Zigzag_Line_2.png\n",
      "Saved image: ./data_continuity/Zigzag_Line_3.png\n",
      "Saved image: ./data_continuity/Straight_Line_4.png\n",
      "Saved image: ./data_continuity/Zigzag_Line_5.png\n",
      "Saved image: ./data_continuity/Curve_Line_6.png\n",
      "Saved image: ./data_continuity/Zigzag_Line_7.png\n",
      "Saved image: ./data_continuity/Zigzag_Line_8.png\n",
      "Saved image: ./data_continuity/Curve_Line_9.png\n",
      "Saved image: ./data_continuity/Curve_Line_10.png\n",
      "Saved image: ./data_continuity/Straight_Line_11.png\n",
      "Saved image: ./data_continuity/Curve_Line_12.png\n",
      "Saved image: ./data_continuity/Curve_Line_13.png\n",
      "Saved image: ./data_continuity/Curve_Line_14.png\n",
      "Saved image: ./data_continuity/Curve_Line_15.png\n",
      "Saved image: ./data_continuity/Straight_Line_16.png\n",
      "Saved image: ./data_continuity/Straight_Line_17.png\n",
      "Saved image: ./data_continuity/Zigzag_Line_18.png\n",
      "Saved image: ./data_continuity/Straight_Line_19.png\n",
      "Saved image: ./data_continuity/Curve_Line_20.png\n",
      "Saved image: ./data_continuity/Zigzag_Line_21.png\n",
      "Saved image: ./data_continuity/Straight_Line_22.png\n",
      "Saved image: ./data_continuity/Straight_Line_23.png\n",
      "Saved image: ./data_continuity/Straight_Line_24.png\n",
      "Saved image: ./data_continuity/Curve_Line_25.png\n",
      "Saved image: ./data_continuity/Curve_Line_26.png\n",
      "Saved image: ./data_continuity/Straight_Line_27.png\n",
      "Saved image: ./data_continuity/Zigzag_Line_28.png\n",
      "Saved image: ./data_continuity/Curve_Line_29.png\n",
      "Saved image: ./data_continuity/Zigzag_Line_30.png\n",
      "Saved image: ./data_continuity/Curve_Line_31.png\n",
      "Saved image: ./data_continuity/Curve_Line_32.png\n",
      "Saved image: ./data_continuity/Zigzag_Line_33.png\n",
      "Saved image: ./data_continuity/Straight_Line_34.png\n",
      "Saved image: ./data_continuity/Zigzag_Line_35.png\n",
      "Saved image: ./data_continuity/Curve_Line_36.png\n",
      "Saved image: ./data_continuity/Curve_Line_37.png\n",
      "Saved image: ./data_continuity/Straight_Line_38.png\n",
      "Saved image: ./data_continuity/Curve_Line_39.png\n",
      "Saved image: ./data_continuity/Straight_Line_40.png\n",
      "Saved image: ./data_continuity/Straight_Line_41.png\n",
      "Saved image: ./data_continuity/Zigzag_Line_42.png\n",
      "Saved image: ./data_continuity/Zigzag_Line_43.png\n",
      "Saved image: ./data_continuity/Straight_Line_44.png\n",
      "Saved image: ./data_continuity/Straight_Line_45.png\n",
      "Saved image: ./data_continuity/Straight_Line_46.png\n",
      "Saved image: ./data_continuity/Zigzag_Line_47.png\n",
      "Saved image: ./data_continuity/Zigzag_Line_48.png\n",
      "Saved image: ./data_continuity/Straight_Line_49.png\n",
      "Saved image: ./data_continuity/Straight_Line_50.png\n",
      "Saved image: ./data_continuity/Curve_Line_51.png\n",
      "Saved image: ./data_continuity/Straight_Line_52.png\n",
      "Saved image: ./data_continuity/Curve_Line_53.png\n",
      "Saved image: ./data_continuity/Zigzag_Line_54.png\n",
      "Saved image: ./data_continuity/Zigzag_Line_55.png\n",
      "Saved image: ./data_continuity/Zigzag_Line_56.png\n",
      "Saved image: ./data_continuity/Curve_Line_57.png\n",
      "Saved image: ./data_continuity/Zigzag_Line_58.png\n",
      "Saved image: ./data_continuity/Straight_Line_59.png\n",
      "Saved image: ./data_continuity/Curve_Line_60.png\n",
      "Saved image: ./data_continuity/Straight_Line_61.png\n",
      "Saved image: ./data_continuity/Zigzag_Line_62.png\n",
      "Saved image: ./data_continuity/Straight_Line_63.png\n",
      "Saved image: ./data_continuity/Straight_Line_64.png\n",
      "Saved image: ./data_continuity/Curve_Line_65.png\n",
      "Saved image: ./data_continuity/Curve_Line_66.png\n",
      "Saved image: ./data_continuity/Curve_Line_67.png\n",
      "Saved image: ./data_continuity/Zigzag_Line_68.png\n",
      "Saved image: ./data_continuity/Curve_Line_69.png\n",
      "Saved image: ./data_continuity/Straight_Line_70.png\n",
      "Saved image: ./data_continuity/Zigzag_Line_71.png\n",
      "Saved image: ./data_continuity/Curve_Line_72.png\n",
      "Saved image: ./data_continuity/Curve_Line_73.png\n",
      "Saved image: ./data_continuity/Zigzag_Line_74.png\n",
      "Saved image: ./data_continuity/Straight_Line_75.png\n",
      "Saved image: ./data_continuity/Zigzag_Line_76.png\n",
      "Saved image: ./data_continuity/Curve_Line_77.png\n",
      "Saved image: ./data_continuity/Zigzag_Line_78.png\n",
      "Saved image: ./data_continuity/Curve_Line_79.png\n",
      "Saved image: ./data_continuity/Curve_Line_80.png\n",
      "Saved image: ./data_continuity/Curve_Line_81.png\n",
      "Saved image: ./data_continuity/Zigzag_Line_82.png\n",
      "Saved image: ./data_continuity/Zigzag_Line_83.png\n",
      "Saved image: ./data_continuity/Zigzag_Line_84.png\n",
      "Saved image: ./data_continuity/Straight_Line_85.png\n",
      "Saved image: ./data_continuity/Straight_Line_86.png\n",
      "Saved image: ./data_continuity/Curve_Line_87.png\n",
      "Saved image: ./data_continuity/Straight_Line_88.png\n",
      "Saved image: ./data_continuity/Curve_Line_89.png\n",
      "Saved image: ./data_continuity/Straight_Line_90.png\n",
      "Saved image: ./data_continuity/Zigzag_Line_91.png\n",
      "Saved image: ./data_continuity/Curve_Line_92.png\n",
      "Saved image: ./data_continuity/Straight_Line_93.png\n",
      "Saved image: ./data_continuity/Curve_Line_94.png\n",
      "Saved image: ./data_continuity/Curve_Line_95.png\n",
      "Saved image: ./data_continuity/Curve_Line_96.png\n",
      "Saved image: ./data_continuity/Straight_Line_97.png\n",
      "Saved image: ./data_continuity/Zigzag_Line_98.png\n",
      "Saved image: ./data_continuity/Zigzag_Line_99.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import math  # Import math for trigonometric functions\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# Create a folder to save generated images\n",
    "def create_data_folder(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        print(f\"Directory created: {path}\")\n",
    "    else:\n",
    "        print(f\"Directory already exists: {path}\")\n",
    "\n",
    "# Function to generate continuity-based shapes\n",
    "def generate_continuity_shapes(image_dir, num_images=100):\n",
    "    create_data_folder(image_dir)\n",
    "\n",
    "    for i in range(num_images):\n",
    "        shape_type = random.choice(['Curve_Line', 'Straight_Line', 'Zigzag_Line'])\n",
    "\n",
    "        if shape_type == 'Curve_Line':\n",
    "            arrangement = [(x, int(50 + 20 * math.sin(x / 10))) for x in range(10, 90, 5)]  # Curve pattern\n",
    "        elif shape_type == 'Straight_Line':\n",
    "            arrangement = [(x, 50) for x in range(10, 90, 5)]  # Straight horizontal line\n",
    "        else:\n",
    "            arrangement = [(x, 50 + (x % 2) * 10) for x in range(10, 90, 5)]  # Zigzag line\n",
    "\n",
    "        output_path = os.path.join(image_dir, f\"{shape_type}_{i}.png\")\n",
    "        create_continuity_object_image(arrangement, shape_type, output_path=output_path)\n",
    "\n",
    "# Function to create continuity-based images\n",
    "def create_continuity_object_image(arrangement, shape_type, image_size=(100, 100), output_path=\"output.png\"):\n",
    "    img = Image.new('L', image_size, color=255)  # Create a white background image\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    for idx in range(len(arrangement) - 1):\n",
    "        draw.line([arrangement[idx], arrangement[idx + 1]], fill=0, width=5)\n",
    "\n",
    "    img.save(output_path)\n",
    "    print(f\"Saved image: {output_path}\")\n",
    "\n",
    "# Generate the continuity dataset\n",
    "continuity_dataset_dir = './data_continuity'\n",
    "generate_continuity_shapes(continuity_dataset_dir, num_images=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5db7e1b",
   "metadata": {},
   "source": [
    "## Define the Dataset Class and Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "007a253c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Custom Dataset class to load continuity-based images and labels\n",
    "class ContinuityShapesDataset(Dataset):\n",
    "    def __init__(self, image_folder, transform=None):\n",
    "        self.image_folder = image_folder\n",
    "        self.image_names = os.listdir(image_folder)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.image_folder, self.image_names[idx])\n",
    "        image = Image.open(img_name).convert('L')  # Convert to grayscale\n",
    "\n",
    "        label_name = self.image_names[idx].split('_')[0]  # e.g., 'Curve' from 'Curve_Line_1'\n",
    "        label_map = {'Curve': 0, 'Straight': 1, 'Zigzag': 2}\n",
    "        label = label_map[label_name]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Define image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((100, 100)),\n",
    "    transforms.ToTensor(),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e29c0f5",
   "metadata": {},
   "source": [
    "## Define the CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72b359db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the CNN Model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes=3):  # We have 3 classes: Curve, Straight, Zigzag\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)  # 1 channel (grayscale images)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 25 * 25, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.ReLU()(self.conv1(x)))\n",
    "        x = self.pool(nn.ReLU()(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 25 * 25)\n",
    "        x = nn.ReLU()(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Setup for device and model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN(num_classes=3).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b599799",
   "metadata": {},
   "source": [
    "## Train the Model on the Generated Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2c0a888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.2565, Accuracy: 49.37%\n",
      "Epoch [2/10], Loss: 0.5644, Accuracy: 79.11%\n",
      "Epoch [3/10], Loss: 0.1355, Accuracy: 100.00%\n",
      "Epoch [4/10], Loss: 0.0139, Accuracy: 100.00%\n",
      "Epoch [5/10], Loss: 0.0008, Accuracy: 100.00%\n",
      "Epoch [6/10], Loss: 0.0001, Accuracy: 100.00%\n",
      "Epoch [7/10], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [8/10], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [9/10], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [10/10], Loss: 0.0000, Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Load the training dataset\n",
    "train_dataset = ContinuityShapesDataset(image_folder=continuity_dataset_dir, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Model, loss, and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, criterion, optimizer, num_epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4254789",
   "metadata": {},
   "source": [
    "## Evaluate the Model on a Separate Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cfd37ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists: ./data_continuity_test\n",
      "Saved image: ./data_continuity_test/Curve_Line_0.png\n",
      "Saved image: ./data_continuity_test/Curve_Line_1.png\n",
      "Saved image: ./data_continuity_test/Curve_Line_2.png\n",
      "Saved image: ./data_continuity_test/Zigzag_Line_3.png\n",
      "Saved image: ./data_continuity_test/Straight_Line_4.png\n",
      "Saved image: ./data_continuity_test/Zigzag_Line_5.png\n",
      "Saved image: ./data_continuity_test/Straight_Line_6.png\n",
      "Saved image: ./data_continuity_test/Zigzag_Line_7.png\n",
      "Saved image: ./data_continuity_test/Zigzag_Line_8.png\n",
      "Saved image: ./data_continuity_test/Straight_Line_9.png\n",
      "Saved image: ./data_continuity_test/Straight_Line_10.png\n",
      "Saved image: ./data_continuity_test/Straight_Line_11.png\n",
      "Saved image: ./data_continuity_test/Curve_Line_12.png\n",
      "Saved image: ./data_continuity_test/Curve_Line_13.png\n",
      "Saved image: ./data_continuity_test/Curve_Line_14.png\n",
      "Saved image: ./data_continuity_test/Zigzag_Line_15.png\n",
      "Saved image: ./data_continuity_test/Zigzag_Line_16.png\n",
      "Saved image: ./data_continuity_test/Zigzag_Line_17.png\n",
      "Saved image: ./data_continuity_test/Curve_Line_18.png\n",
      "Saved image: ./data_continuity_test/Curve_Line_19.png\n",
      "Test Accuracy: 100.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate test dataset\n",
    "test_dataset_dir = './data_continuity_test'\n",
    "generate_continuity_shapes(test_dataset_dir, num_images=20)\n",
    "\n",
    "# Load the test dataset\n",
    "test_dataset = ContinuityShapesDataset(image_folder=test_dataset_dir, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define evaluation function\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "    return accuracy\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "evaluate_model(model, test_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
